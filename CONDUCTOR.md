# CONDUCTOR.md
<!-- Generated by Claude Conductor v1.1.2 -->

This file helps maintain consistency and quality when working with MonkeyOCR's codebase.

## Project Overview
**MonkeyOCR** is an advanced document parsing system using a Structure-Recognition-Relation (SRR) triplet paradigm. It processes PDFs and images to extract text, formulas, tables, and complex layouts with high accuracy, supporting both English and Chinese documents.

## Architecture Highlights
### Three-Stage Pipeline
1. **Structure Detection** - YOLO-based layout analysis to identify document components
2. **Content Recognition** - 3B parameter vision-language model for content extraction  
3. **Relation Prediction** - Reading order and relationship determination

### Key Components
- `magic_pdf/` - Core OCR processing library
- `api/` - FastAPI server for REST API
- `monkeyocr-web/` - Next.js web interface
- `model_weight/` - Pre-trained ML models
- `demo/` - Gradio demonstration interface

## Code Standards
### Python Guidelines
- Python â‰¥3.9 required
- Follow PEP 8 style guide
- Use type hints for function signatures
- Document complex algorithms with docstrings
- Handle CUDA/CPU/MPS device selection gracefully

### TypeScript/JavaScript Guidelines
- Use TypeScript for all new code
- Follow Next.js best practices
- Implement proper error boundaries
- Use Tailwind CSS for styling
- Validate all user inputs

### Security Requirements
- Never hardcode API keys or credentials
- Validate all file paths to prevent traversal
- Implement proper CORS configuration
- Add authentication before production deployment
- Sanitize all user inputs
- Use environment variables for configuration

## Common Workflows
### Adding a New Document Type
1. Add training data to appropriate directories
2. Update model configuration in `model_configs.yaml`
3. Implement specific operators if needed
4. Test with sample documents
5. Update documentation

### Debugging OCR Issues
1. Enable debug mode in `parse.py`
2. Check intermediate outputs in temp directory
3. Verify model loading and device selection
4. Examine block detection visualizations
5. Review confidence scores

### Performance Optimization
1. Profile with cProfile or PyTorch profiler
2. Adjust batch sizes in model config
3. Enable model caching for API server
4. Implement async processing where possible
5. Monitor memory usage on GPU

## Testing Strategy
### Unit Tests
- Test individual operators and utilities
- Mock model outputs for deterministic testing
- Validate markdown conversion accuracy

### Integration Tests
- Test full pipeline with sample PDFs
- Verify API endpoint responses
- Check web interface functionality

### Performance Tests
- Benchmark processing speed (target: 0.84 pages/sec)
- Monitor memory usage under load
- Test concurrent request handling

## Deployment Checklist
### Pre-deployment Security
- [ ] Implement API authentication
- [ ] Configure CORS properly (not "*")
- [ ] Validate all environment variables
- [ ] Remove debug endpoints
- [ ] Enable HTTPS only
- [ ] Add rate limiting

### Model Deployment
- [ ] Download all required model weights
- [ ] Verify CUDA compatibility
- [ ] Set appropriate batch sizes
- [ ] Configure model caching
- [ ] Test on target hardware

### Infrastructure
- [ ] Configure Docker resource limits
- [ ] Set up health check endpoints
- [ ] Implement logging and monitoring
- [ ] Configure automatic temp file cleanup
- [ ] Set up backup for model weights

## Error Handling
### Common Issues
1. **CUDA Out of Memory** - Reduce batch size or use CPU
2. **Model Loading Failure** - Check model paths and permissions
3. **PDF Processing Error** - Validate PDF structure
4. **API Timeout** - Increase timeout or optimize processing
5. **Frontend Connection Issues** - Verify CORS and proxy settings

### Debugging Tools
- Enable verbose logging with environment variables
- Use visualization outputs for layout debugging
- Check intermediate JSON outputs
- Monitor GPU memory with nvidia-smi
- Use browser dev tools for frontend issues

## Performance Benchmarks
- **V100 GPU**: ~0.84 pages/second
- **RTX 3090**: ~0.65 pages/second
- **CPU Mode**: ~0.1 pages/second
- **Memory Usage**: 8-12GB GPU RAM
- **API Latency**: <100ms overhead

## Future Enhancements
### Planned Features
- Multi-GPU support for large documents
- Real-time streaming API
- Additional language support
- Enhanced table structure recognition
- Formula editing capabilities

### Technical Debt
- Add comprehensive test coverage
- Implement proper API authentication
- Refactor monolithic processing functions
- Optimize memory usage for large PDFs
- Add telemetry and analytics

## Contribution Guidelines
### Code Submission
1. Create feature branch from main
2. Write tests for new functionality
3. Update relevant documentation
4. Run security checks
5. Submit PR with detailed description

### Review Process
- Code review required for all changes
- Security review for API changes
- Performance testing for algorithm changes
- Documentation update verification
- Integration test validation

## Security Contacts
For security vulnerabilities:
- Do not create public issues
- Follow responsible disclosure
- Contact maintainers directly
- Allow time for patch development

## Resource Links
- [Model Download Instructions](scripts/download_models.py)
- [API Documentation](API.md)
- [Deployment Guide](PLAYBOOKS/DEPLOY.md)
- [Architecture Details](ARCHITECTURE.md)
- [Contributing Guide](CONTRIBUTING.md)